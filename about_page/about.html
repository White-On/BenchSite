<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="about.css">
    <title>About</title>
</head>
<body>
    <div class="card right">
        <div class="card-text">
            <h2>What is GeneratedVelocity</h2>
            <p>GeneratedVelocity is a platform designed to <b>compare the performance of different libraries and frameworks</b>. It
                provides a detailed report of each library's speed, precision, and other parameters, making it easier for
                developers to choose the best library for their project.
            </p>
        </div>
        <div class="media">
            <p class="card-text">Lorem ipsum dolor, sit amet consectetur adipisicing elit. Accusantium tempora aperiam dolor ex officiis nemo dicta perferendis in aliquam reiciendis suscipit consectetur dignissimos, molestias ea similique quaerat laudantium amet ullam!</p>
        </div>
    </div>

    <div class="card left">
        <div class="card-text">
            <h2>Why Creating this tool</h2>
            <p>GeneratedVelocity was initiated to address the need for a reliable and unbiased way of <b>
                comparing the
                    performance of different libraries
            </b>. With so many options available in the market, it can be challenging to
                choose the right library for a particular task. This tool aims to simplify the selection process by providing a
                standardized benchmarking methodology for all libraries.
            </p>
        </div>
        <div class="media">
            <p class="card-text left">Lorem ipsum dolor, sit amet consectetur adipisicing elit. Accusantium tempora aperiam dolor ex officiis nemo dicta perferendis in aliquam reiciendis suscipit consectetur dignissimos, molestias ea similique quaerat laudantium amet ullam!</p>
        </div>
    </div>

    <div class="card right">
        <div class="card-text">
            <h2>How work GeneratedVelocity</h2>
            <p>GeneratedVelocity is designed to automate the process of comparing and testing different libraries. To
                achieve this, test are writen in configuration files, then given to GeneratedVelocity. The tests are executed in a
                controlled environment, and the results are then analyzed and compiled into easy-to-read reports. These reports
                are published on dedicated GitHub pages, where users can access them and see how the different libraries perform
                in a variety of scenarios. By automating the testing process, the website enables developers to save time and
                effort when evaluating libraries, and helps them make informed decisions based on reliable data.
            </p>
        </div>
        <div class="media">
            <img src="infrastructure_explanations.png" width="100%" alt="graph explaning the structure of the directory needed to create a benchmark">
        </div>
    </div>

    <div class="card left">
        <div class="card-text">
            <h2 id="compare-explanation">How we compare the targets</h2>
            <p>For the time being, we we decided to compare results base on the <b>Lexicographic Maximal Ordering Algorithm (LexMax)</b>.
                each ranking is based on the number of wins, ties, and losses of each library. The library with the highest
                number of wins is ranked first, followed by the library with the second-highest number of wins, and so on. In
                the case of a tie, both libraries are ranked equally. The algorithm does not take into account the magnitude of the wins or losses, only the number of them.<br><br>
                We use it to compare all the data generated by the benchmarking process. For exemple, we run a task on a set of
                libraries, and we get the results. Each result is compare to the other result with the same argument and we get a
                score for each arguments. On the entire task, we get a vector of score for each library. We use the LexMax
                algorithm to compare the vector of score of each library and we get a ranking of the libraries for that task.
                We do this for each task and repeat for the theme and the global ranking.
            </p>
        </div>
        <div class="media">
            <video controls width="100%" autoplay loop>
                <source src="explanation.mp4" type="video/mp4">
                <p>Your browser does not support the video tag.</p>
            </video>
        </div>
    </div>

    <div class="card right">
        <div class="card-text">
            <h2>How to contribute</h2>
            <p>The benchmark website is an open-source project, and contributions from the community are welcome. To contribute,
                users can fork the project on GitHub, make changes to the code, and submit a pull request. Users can also
                contribute by reporting bugs, suggesting improvements, or sharing their benchmarking results.
            </p>
        </div>
        <div class="media">
            <p class="card-text">Lorem ipsum dolor, sit amet consectetur adipisicing elit. Accusantium tempora aperiam dolor ex officiis nemo dicta perferendis in aliquam reiciendis suscipit consectetur dignissimos, molestias ea similique quaerat laudantium amet ullam!</p>
        </div>
    </div>
</body>
</html>